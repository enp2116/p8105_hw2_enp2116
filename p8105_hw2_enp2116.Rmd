---
title: "p8105_hw2_enp2116"
author: "Emily Potts"
date: "2022-09-27"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

# Problem 1

Reading and cleaning the data; retaining line, station, name, station latitude / longitude, routes served, entry (logical), vending, entrance type, and ADA compliance: 
```{r, message=FALSE}
nyc_transit_data =
  read_csv("./NYC_Transit_Subway_Entrance_And_Exit_Data.csv", col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

The cleaned NYC transit dataset contains the variables: `r names(nyc_transit_data)`. Thusfar, I have cleaned the data by turning all variable names into lower- and camel-case, selecting only the variables asked for, and recoding the entry variable as logical. The `NYC Transit` dataset has `r nrow(nyc_transit_data)` rows and `r ncol(nyc_transit_data)` columns, indicating we have data on  `r nrow(nyc_transit_data)` different entrances or exits and want to look at `r ncol(nyc_transit_data)` different traits in each of these. These data are not yet tidy, as we have 11 "route" variables (for each of the routes offered at a given entrance or exit), which can be condensed into two columns to be tidy.

* Distinct stations:
```{r}
nyc_transit_data %>% 
  select(station_name, line) %>% 
  distinct %>% 
  nrow()
```


* ADA compliant stations:
```{r}
nyc_transit_data %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct %>% 
  nrow()
```


* The proportion of station entrances / exits without vending allow entrance:
```{r}
nyc_transit_data %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```


Reformatting dataset so that route number and route name are distinct variables:
```{r, message=FALSE}
  tidy_nyc_transit_data =
  nyc_transit_data %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route_name")
```

* How many distinct stations serve the A train?
```{r, echo=FALSE}
tidy_nyc_transit_data %>%
  filter(route_name == "A") %>% 
  select(station_name, line) %>% 
  distinct %>% 
  nrow()
```

* Of the stations that serve the A train, how many are ADA compliant?
```{r, echo=FALSE}
tidy_nyc_transit_data %>%
  filter(route_name == "A", ada == TRUE) %>%
  select(station_name, line) %>% 
  distinct() %>% 
  nrow()
```


# Problem 2

Reading and cleaning the Mr. Trash Wheel sheet:
```{r}
mr_trash_wheel =
  read_excel(
    "./Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet = "Mr. Trash Wheel",
    range = "A2:N533") %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls, 0)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

Reading and cleaning the Professor Trash Wheel sheet:
```{r}
prof_trash_wheel =
  read_excel(
    "./Trash-Wheel-Collection-Totals-7-2020-2.xlsx",
    sheet = "Professor Trash Wheel",
    range = "A2:N115") %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = round(sports_balls, 0)) %>% 
  mutate(sports_balls = as.integer(sports_balls))
```

Combining the Mr. Trash Wheel & Professor Trash Wheel datasets to produce a single tidy dataset (tidy_trash_wheel):
```{r}
mr_trash_wheel = 
  mutate(mr_trash_wheel, trash_wheel_type = "mr_trash_wheel")

prof_trash_wheel = 
  mutate(prof_trash_wheel, trash_wheel_type = "prof_trash_wheel")

tidy_trash_wheel = 
  bind_rows(mr_trash_wheel, prof_trash_wheel) %>%
  janitor::clean_names() 
```

The combined trash wheel dataset contains the variables: `r names(tidy_trash_wheel)` and has `r nrow(tidy_trash_wheel)` total observations. Data were collected from the two datasets: `r unique(tidy_trash_wheel$trash_wheel_type)`. The variable of weight_tons has values such as `r head(tidy_trash_wheel$weight_tons)` tons and sports_balls has values such as `r head(tidy_trash_wheel$sports_balls)`, measuring the number of sports balls present in each dumpster. 

* For available data, what was the total weight of trash collected by Professor Trash Wheel? 

```{r, echo=FALSE}
tidy_trash_wheel %>%
  filter(trash_wheel_type == "prof_trash_wheel") %>%
  select(weight_tons) %>%
  sum()
```

* What was the total number of sports balls collected by Mr. Trash Wheel in 2020?
```{r, echo=FALSE}
tidy_trash_wheel %>%
  filter(trash_wheel_type == "mr_trash_wheel", year == "2020") %>%
  select(sports_balls) %>%
  sum()
```


# Problem 3
Using the data in pols-month.csv, unemployment.csv, and snp.csv with the goal to merge these into a single data frame using year and month as keys across datasets.

Cleaning the data in pols-month.csv:
```{r, message=FALSE}
pols_month_data =
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  separate(mon, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(month = recode(month, "01" = "jan", "02" = "feb", "03" = "mar", "04" = "apr", "05" = "may", "06" = "jun", "07" = "jul", "08" = "aug", "09" = "sep", "10" = "oct", "11" = "nov", "12" = "dec")) %>% 
  mutate(
    president = case_when(prez_dem == 1 ~ 'dem',
                          prez_gop == 1 ~ 'gop')) %>% 
  select(-c(prez_dem, prez_gop, day))

```


Second, cleaning the data in snp.csv using a similar process to the above. For consistency across datasets, arranging according to year and month, and organizing so that year and month are the leading columns:
```{r, message=FALSE}
snp_data =
  read_csv("./fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  separate(date, into = c("month", "day", "year"), sep = "/") %>% 
  mutate(month = recode(month, "1" = "jan", "2" = "feb", "3" = "mar", "4" = "apr", "5" = "may", "6" = "jun", "7" = "jul", "8" = "aug", "9" = "sep", "10" = "oct", "11" = "nov", "12" = "dec")) %>% 
  relocate(year, month) %>% 
  arrange(year, month) %>% 
  mutate(
    year_prefix = case_when(year < 16 ~ 20,
                          year > 49 ~ 19)) %>% 
  mutate(year = paste(year_prefix, year, sep = "")) %>%
    select(-c(year_prefix, day))
```

Third, tidying the unemployment data so that it can be merged with the previous datasets:
```{r, message=FALSE}
unemployment_data =
  read_csv("./fivethirtyeight_datasets/unemployment.csv") %>%
  janitor::clean_names() %>% 
  pivot_longer(
    jan:dec,
    names_to = "month", 
    values_to = "unemployment rate") %>% 
  mutate(
    year = as.character(year)
  )
```


Joining the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
snp_pols_data = 
  left_join(pols_month_data, snp_data, by = c("year", "month"))

snp_pols_unemp_data = 
  left_join(snp_pols_data, unemployment_data, by = c("year", "month"))
```

The tidy `pols-month` dataset contained `r nrow(pols_month_data)` rows and `r ncol(pols_month_data)` columns, meaning `r nrow(pols_month_data)` total observations and `r ncol(pols_month_data)` variables measured. This dataset contained information from years: `r range(pols_month_data$year)`, including variables that measured political standing across governors, senators, representatives, and presidents for the given each month and year. Variables such as gov_dem took values such as `r head(pols_month_data$gov_dem)` (representing the number of democratic governors) and the variable of president took values of `r unique(pols_month_data$president)`.

The tidy `snp` dataset contained `r nrow(snp_data)` rows and `r ncol(snp_data)` columns, meaning `r nrow(snp_data)` total observations and `r ncol(snp_data)` variables measured. This dataset contained information from years: `r range(snp_data$year)`. The key variable here is close, which measured the closing values of the S&P stock index on the associated date. This variable took on values such as `r head(snp_data$close)`.

The tidy `unemployment` dataset contained `r nrow(unemployment_data)` rows and `r ncol(unemployment_data)` columns, meaning `r nrow(unemployment_data)` total observations and `r ncol(unemployment_data)` variables measured. This dataset contained information from years: `r range(unemployment_data$year)`. The key variable here is the unemployment_rate, which took on values such as `r head(unemployment_data$unemployment_rate)`.

The resulting dataset, which was formed by merging the `pols-month`, `snp`, and `unemployment` datasets using year and month as keys, contained `r nrow(snp_pols_unemp_data)` rows and `r ncol(snp_pols_unemp_data)` columns, meaning `r nrow(snp_pols_unemp_data)` total observations and `r ncol(snp_pols_unemp_data)` variables measured. This dataset contained information from years: `r range(snp_pols_unemp_data$year)` and looked at the variables of `r names(snp_pols_unemp_data)`. 
